（2017.4.12）

针对回归和分类

分类模型的评价：


  1.考虑一个二分问题，即将实例分成正类（positive）或负类（negative）。对一个二分问题来说，会出现四种情况。如果一个实例是正类并且也被 预测成正类，即为真正类（True positive）,如果实例是负类被预测成正类，称之为假正类（False positive）。相应地，如果实例是负类被预测成负类，称之为真负类（True negative）,正类被预测成负类则为假负类（false negative）。

  TP：正确肯定的数目； - label is positive and prediction is also positive
  FN：漏报，没有正确找到的匹配的数目； - label is negative and prediction is also negative
  FP：误报，给出的匹配是不正确的； - label is negative but prediction is positive
  TN：正确拒绝的非匹配对数 - label is positive but prediction is negative



  召回率：recall    = TP / (TP + FN)

  精确率：precision = TP / (TP + FP)
        模型判为正的所有样本中有多少是真正的正样本

  准确率：accuracy = (TP + TN) / (TP + FP + TN + FN)
        反映了分类器对整个样本的判定能力——能将正的判定为正，负的判定为负


  如何在precision和Recall中权衡？

    F1 Score = P*R/2(P+R)，其中P和R分别为 precision 和 recall

    在precision与recall都要求高的情况下，可以用F1 Score来衡量



ROC曲线和AUC：

  有时候我们需要在精确率与召回率间进行权衡， 调整分类器threshold取值，以FPR（假正率False-positive rate）为横坐标，TPR（True-positive rate）为纵坐标做ROC曲线；

  Area Under roc Curve(AUC)：处于ROC curve下方的那部分面积的大小，通常AUC的值介于0.5到1.0之间，较大的AUC代表了较好的性能；

  精确率和召回率是互相影响的，理想情况下肯定是做到两者都高，但是一般情况下准精确率、召回率就低，召回率低、精确率高，当然如果两者都低，那是什么地方出问题了
  2 Bisecting k-means聚类算法实现 http://shiyanjun.cn/archives/1388.html?utm_source=tuicool&utm_medium=referral



先去看聚类～～  改日再来

：https://github.com/wangpeng1/sparkPdf/blob/12908437a3124bab61337c2ad0b4678073607cde/document

http://spark.apache.org/docs/latest/mllib-evaluation-metrics.html











MulticlassMetrics 以不同方式计算分类器预测质量的标准指标,
BinaryClassificationMetrics 它提供类似MulticlassMetrics的评价指标实现,不过仅适用常见的类别型目标只有两个可能取值的情况。
