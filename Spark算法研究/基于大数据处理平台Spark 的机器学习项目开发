
（二）基于大数据处理平台Spark 的机器学习项目开发（大学期间科研项目| 2013-2017）：
（1）··电影推荐    （个人博客http://blog.csdn.net/lovebyz/article/details/51784397）
    场景：预测人们可能喜好的电影并通过探寻电影之间的联系。
    主要方法：基于Spark ALS协同过滤算法，计算给定用户对某个物品的预计评级，使用用户因子矩阵和物品因子矩阵的点积； 物品之间的推荐采用相似度计算，基于用户推荐则是用相识用户的评级来计算某用户的推荐。
    评估方法：regressionMetrics--均方差/均方根误差、rankingMetrics--K值平均准确率
（2）··音乐推荐  · 数据集为隐式数据，隐式模型也像显式模型创建一个用户因子矩阵和物品因子矩阵，但输入的评级数据为两个矩阵：一个二元偏好矩阵和一个信心权重矩阵，即对物品是否做过和做过的次数。
    主要方法：ALS.trainImplicit()
    评估方法：用BinaryClassificationMetrics.AUC 计算ROC曲线的面积均值求准确率
（3）··网络流量异常检测+R可视化--（K-Means/rgl-Rpackge）
    场景：网络攻击越来越多的见诸报端，有些入侵方式是已知的，如连续不断的访问某个机器的所有端口，统计各端口在短时间内被远程访问的次数，得到一个特征，可以很好的预测端口扫描攻击，这些特征包括发送与接收的字节数/TCP错误数/登录次数等，都包含在数据集中。  算法：使用K-Means聚类根据每个网络连接的统计属性进行聚类识别异常网络连接。
（4）··新闻组数据分类。使用提取的文本特征作为分类模型的训练输入--(TF-IDF/W2V/贝叶斯）
（5）··潜在语义分析算法分析维基百科--（TF-IDF/Word2Vec/SVD）
    场景：新闻组数据集有不同主题的新闻消息组信息组成，维基百科数据在维基百科中下载，二者都用来做文本分类。
    主要用到方法：HashingTF、IDF、Word2Vec、BinaryClassificationMetrics做模型评估、分词（切分每一个文档的原始内容为多个单词-词项）、移除停用词（过滤掉指定词组、使用TF-IDF加权模式分析单词权重）     
（6）··自行车出租次数外部因素(温度/季节/日期/时间/..)分析--(最小二乘/决策树回归)
    场景：数据集记录了bike sharing系统每小时自行车的出租次数，还包括日期、天气、季节和节假日的相关信息。使用最小二乘/决策树回归的方法预测自行车出租次数外部影响因素，以增加用户量。
    主要用到方法：1-of-k特征向量到二元向量的映射，类型特征转换为数值特征、LinearRegressionWithSGD.train()、DecisionTree.traiRegressor()、L1/L2正则化、模型参数调优、MSE/RMSE/MAE进行模型性能评估
（7）··分析面部图像数据主成分用于分类聚类等模型--（PCA/SVD）
   代码实现文章链接： http://blog.csdn.net/lovebyz/article/details/51307368
（8）··森林植被预测-科罗拉多州不同地块的森林植被类型--（决策树/随机森林）
   场景：根据美国科罗拉州不同地块的森林植被类型数据，包括地理位置和土壤的化学成分、海拔、坡度、到水源距离、土壤类型等预测森林植被。        主要用到方法：LabeledPoint()、1-of-k 、DecisionTree.trainClassifier()、用MulticlassMetrics以不同的方式计算分类器预测质量的标准指标、 随机决策森林构造RandomForest.trainClassifier()、最后是参数调优




