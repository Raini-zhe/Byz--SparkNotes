

谱聚类的优势是解决(高维)数据和(稀疏)数据的聚类问题--涉及到降维


若干概念：
	1. 无向图 G=(V,E)  --因为（ a点->b点，和b->a 的相似度是一样的，所以得到一个无向图
	2. 邻接矩阵 W=(W ij) i,j=1,...,n         --因为（ 某一个点有若干个点和其连接
	3. 顶点的度di -> 度矩阵D(对角阵)
		：和这个点连接的所有点的权值加和



相似度图G的构建方法：
	1. 全连接图
		：高斯相似度函数--（距离越大，相似度越小
		：可以建立很好的权值矩阵，缺点是建立的矩阵不是稀疏的
	2. 3近邻图
		：数据密度不一样时，高斯部分很多都没连接-- 缺点
	3. k近邻图
		: （应用～ 提取文本k个紧邻词作为Vi所相连的顶点）
		：k=5,即该点连接的第6个顶点就不要了。利用KNN算法遍历所有的样本点，取每个样本最近的k个点作为近邻，只有和样本距离最近的k个点之间的 wij>0 。
		：最后要忽略方向
		：（优先考虑）
	4. 互k近邻
		：两者都连接的才算近邻
		：数据密度不一样时，连接蛮好的



拉普拉斯矩阵及其性质：
	1. 矩阵 L = D(度矩阵) - W(通过各种方法得到的对称阵)    ， 所以L还是对角阵







步骤：
	1. G - 相似度图
	2. W - 权值矩阵
	3. D
	4. L
	5. 计算前k个特征向量，得到一个n行k列的 矩阵 U(u1..uk)，-- 最小的k个特征值所对应的特征向量，若k取比较大，其实是升维了。
		每个点都对应u矩阵的一行，可以方便把聚类结果对应回来。--矩阵的维数是点的个数
	6. 取U的第1到k行，把y1,y2,..,yn看作有n个点，对于这n个点总可以通过k均值的方法去求的聚类c1,c2,..,ck （c1可能包含有y1,y3,y5..）
	7. 





拉普拉斯矩阵求正则化：
	对称拉普拉斯矩阵（Ncut切图）
		L = D(-1/2) L D(-1/2) = I - D(-1/2) W D(-1/2)  --D乘负1/2次方，仍然是一个对称矩阵--对称拉普拉斯矩阵

		可以发现这个式子和RatioCut基本一致，只是中间的L变成了（D−1/2 L D−1/2）。
		这样我们就可以继续按照RatioCut的思想，求出D−1/2LD−1/2的最小的前k个特征值，然后求出对应的特征向量，并标准化，得到最后的特征矩阵F,最后对F进行一次传统的聚类（比如K-Means）即可。

	随机游走拉普拉斯矩阵(推荐使用)
		L = D(-1) L = I - D(-1) W




切割图：
	对于定值k和图G，选择一组划分：A1,A2,..,Ak，最小化这个式子：cut(A1,..,Ak)=1/2 W(Ai,Ai补集) --所有的连接权相加 除以2， 让剪切的代价最小

	：实际中，会使上式 W(Ai,Ai补集) 除以|Ai|的数目  --即（对称拉普拉斯矩阵
				  或者 除以vol(Ai)的度 --即（随机游走拉普拉斯矩阵




补充：
	k均值---只能聚类凸形状
	谱聚类--原始数据可能是凹的，映射到高维了之后就有可能变成凸的了






　　　　一般来说， D−1/2LD−1/2D−1/2LD−1/2相当于对拉普拉斯矩阵LL做了一次标准化，即Lijvol(Ai)vol(Aj)√Lijvol(Ai)vol(Aj)

7. 谱聚类算法流程

　　　　铺垫了这么久，终于可以总结下谱聚类的基本流程了。一般来说，谱聚类主要的注意点为相似矩阵的生成方式（参见第二节），切图的方式（参见第六节）以及最后的聚类方法（参见第六节）。

　　　　最常用的相似矩阵的生成方式是基于高斯核距离的全连接方式，最常用的切图方式是Ncut。而到最后常用的聚类方法为K-Means。下面以Ncut总结谱聚类算法流程。

　　　　输入：样本集D=(x1,x2,...,xn)(x1,x2,...,xn)，相似矩阵的生成方式, 降维后的维度k1k1, 聚类方法，聚类后的维度k2k2
　　　　输出： 簇划分C(c1,c2,...ck2)C(c1,c2,...ck2).　

　　　　1) 根据输入的相似矩阵的生成方式构建样本的相似矩阵S

　　　　2）根据相似矩阵S构建邻接矩阵W，构建度矩阵D

　　　　3）计算出拉普拉斯矩阵L

　　　　4）构建标准化后的拉普拉斯矩阵D−1/2LD−1/2
　　　　5）计算D−1/2LD−1/2最小的k1k1个特征值所各自对应的特征向量ff
　　　　6) 将特征向量ff标准化，最终组成n×k1维的特征矩阵F

　　　　7）对F中的每一行作为一个k1k1维的样本，共n个样本，用输入的聚类方法进行聚类，聚类维数为k2k2。

　　　　8）得到簇划分C(c1,c2,...ck2)C(c1,c2,...ck2).　　　　　　　　　



8. 谱聚类算法总结

　　　　谱聚类算法是一个使用起来简单，但是讲清楚却不是那么容易的算法，它需要你有一定的数学基础。如果你掌握了谱聚类，相信你会对矩阵分析，图论有更深入的理解。同时对降维里的主成分分析也会加深理解。

　　　　下面总结下谱聚类算法的优缺点。

　　　　谱聚类算法的主要优点有：

　　　　1）谱聚类只需要数据之间的相似度矩阵，因此对于处理稀疏数据的聚类很有效。这点传统聚类算法比如K-Means很难做到

　　　　2）由于使用了降维，因此在处理高维数据聚类时的复杂度比传统聚类算法好。

　　　　谱聚类算法的主要缺点有：

　　　　1）如果最终聚类的维度非常高，则由于降维的幅度不够，谱聚类的运行速度和最后的聚类效果均不好。

　　　　2) 聚类效果依赖于相似矩阵，不同的相似矩阵得到的最终聚类效果可能很不同。








//---

NP问题-- 找到H使得tr(H′LH)尽量小。（使用降维，得到每行k个元素）

	现在我们得到了放宽限制条件下的优化问题的最优解解h1,⋯hK,如何得到原问题的一个解？

	我们知道，如果H满足原来的限制条件，那么hij≠0表示第i个样本归为第j类，但是我们放宽限制条件后得到的H可能一个零都没有！


	谱聚类有意思的地方是选择了对H的行向量做K-means聚类，我个人认为是基于如下考虑：

		对满足原始限制条件的H，行向量一致等价于类别一致
		在原始限制条件下得到的H跟放宽限制条件下得到的H应该比较相近
		如此可以推断在放宽条件下得到的H如果行向量相似，则应该类别相似。因此直接对行向量做k-means聚类即可。









